Abstract— Customer service centers require efficient call summarization to track interactions, escalate issues, and enhance service quality. This research proposes an automated Customer Call Summarizer using an LLM API for speech-to-text, Pyannote-audio for speaker diarization, and RoBERTa/BERT with Librosa for sentiment analysis. KeyBERT and NLTK/SpaCy extract key topics, while Librosa detects background sounds. An open-source LLM generates detailed summaries, reducing manual effort and improving accuracy. Results show effective mood analysis, key topic extraction, background sound detection, speaker identification, and detailed reporting, significantly improving customer tracking and escalation handling. The paper details the methodology, implementation, and evaluation of this AI-driven approach.
Keywords— Customer Call Summarization, Speech-to-Text (STT), Speaker Diarization, Sentiment Analysis, Natural Language Processing (NLP), AI in Customer Service, Call Center Automation, Topic Extraction, Large Language Models (LLMs), Customer Interaction Tracking.
I.	INTRODUCTION (HEADING 1)
In today’s world, customer interactions are at the heart of every business, whether it’s a call centre resolving issues, a marketing team pitching a product, or a company simply trying to understand its audience better. But with countless conversations happening every day, how do businesses make sense of it all? How can they truly understand their customers—what they feel, what they need, and how they respond to different situations?
That’s where our AI-driven conversation analysis model comes in. Designed to help businesses, marketing teams, and customer service centres, this model listens, analyses, and extracts key insights from conversations. It doesn’t just summarise what was said; it understands the tone, detects emotions, and evaluates how well a customer’s concerns were addressed. More than that, it helps businesses determine whether a follow-up is needed, whether there’s an opportunity to introduce another product, or how a situation could have been handled better.
This research presents an AI-powered system that automates call summarization by leveraging an LLM API for speech-to-text, Pyannote-audio for speaker diarization, and RoBERTa/BERT with Librosa for sentiment detection. Additionally, KeyBERT and NLTK/SpaCy extract key topics, while Librosa analyzes background sounds, enhancing contextual understanding. An open-source LLM generates structured call summaries, reducing the need for manual processing. The proposed system has several practical applications in customer service environments. By automating call documentation, it significantly reduces the workload of customer service representatives while ensuring accurate tracking of customer requests. It also improves escalation handling by detecting urgent concerns through sentiment analysis and keyword extraction, allowing for faster response times. In sales and marketing, the system provides insights into customer interests and engagement, aiding in the delivery of personalized sales pitches. Additionally, it ensures compliance with regulatory and quality standards by providing structured reports that can be reviewed for accuracy and adherence to company policies. Furthermore, integrating the system with customer relationship management (CRM) platforms allows businesses to maintain a detailed history of customer interactions, leading to more personalized and effective customer support.
By reducing manual effort, improving report accuracy, and enabling better tracking of customer interactions, this system enhances the overall efficiency of customer service operations. It optimizes service quality, facilitates informed decision-making, and improves customer satisfaction. This paper details the methodology, implementation, and evaluation of the proposed model, demonstrating how AI-driven automation can transform customer service processes.
II.	LITERATURE SURVEY
In the digital age, customer interactions are no longer confined to face-to-face meetings or simple phone calls. Businesses now communicate with customers through emails, social media, chatbots, and call centres, generating vast amounts of conversational data every day. However, understanding and extracting meaningful insights from these interactions remains a challenge. Traditionally, businesses have relied on surveys, feedback forms, and manual call monitoring to gauge customer sentiment and service effectiveness [1]. While these methods offer some insights, they are time-consuming, prone to human bias, and incapable of real-time analysis [2]. 
With advancements in artificial intelligence (AI) and natural language processing (NLP), businesses now have the ability to automatically analyse conversations, detect emotional cues, and derive actionable insights. AI-driven conversation analytics provides a more comprehensive and scalable solution, allowing companies to enhance customer service, improve marketing strategies, and optimise problem resolution in ways that were previously unattainable.
Sentiment analysis is at the core of AI-driven conversation analysis. It enables systems to understand the tone and emotional intent behind customer messages. Early models, such as those developed by [3][4], primarily focused on classifying sentiments as positive, negative, or neutral. While these methods laid the groundwork for AI-driven sentiment detection, they often failed to grasp the complexity of human emotions, especially in nuanced or mixed-expression conversations. 
Recent advancements, particularly in deep learning, have significantly improved sentiment analysis. Techniques like Bidirectional Encoder Representations from Transformers (BERT) and Long Short-Term Memory (LSTM) networks allow AI models to process conversations more contextually and detect subtle emotional cues [5]. Studies by Cambria [6] further highlight how multimodal approaches—combining voice tone, speech patterns, and textual data—enhance the accuracy of sentiment detection. However, despite these advancements, many existing models still struggle with sarcasm, cultural variations in expression, and shifting emotions within a single conversation.
 While sentiment analysis is an essential component, truly valuable conversation analysis goes beyond just detecting emotions. Businesses need deeper insights—such as conversation flow, customer intent, resolution effectiveness, and follow-up opportunities—to optimize their interactions. AI-powered analytics tools like those proposed by Mehrotra [7] aim to capture these aspects, providing businesses with structured reports that highlight key trends in customer interactions.
 A major development in this area is real-time conversation monitoring, where AI listens to calls or chats and offers live recommendations to agents. Research by Gupta [8] shows that AI-assisted customer service representatives perform significantly better in resolving issues efficiently while maintaining customer satisfaction. AI models can detect moments of frustration, identify when a conversation is going off track, and even suggest alternative responses to improve engagement. However, while AI can enhance decision-making, complete automation of customer interactions remains a challenge due to the need for human empathy and adaptability in complex scenarios.
Call centres, one of the largest beneficiaries of AI-driven conversation analysis, have traditionally relied on speech-to-text transcription and keyword-based sentiment analysis to evaluate agent performance [9]. However, recent NLP advancements allow for deeper analysis of customer-agent dynamics, helping businesses not only assess past interactions but also predict future behaviors. Studies by Ganin [10] indicate that AI-powered call centre analytics can identify patterns in recurring customer complaints, enabling businesses to address root causes before they escalate. 
In marketing, AI-driven conversation analysis is used to assess how customers respond to advertisements, social media campaigns, and personalized recommendations. Research by Chatterjee [11] highlights how businesses are leveraging AI to track customer sentiment in response to marketing messages, helping them fine-tune their branding and communication strategies. However, most current solutions focus on either customer service or marketing analytics separately. Few studies explore integrated AI systems that analyse both service interactions and marketing engagements to provide a holistic view of customer behaviour.
As AI becomes more involved in analysing human conversations, ethical concerns regarding privacy, data security, and algorithmic bias have emerged. Many AI models rely on large datasets, often collected from real customer interactions, raising questions about consent and data protection [12]. The implementation of AI-driven analytics must align with regulatory frameworks such as GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act) to ensure responsible data handling.
 Another major challenge is algorithmic bias. AI models trained on imbalanced datasets may develop biases that skew sentiment analysis results, leading to unfair assessments or incorrect predictions [13]. Addressing these concerns requires ongoing refinement of AI models, inclusion of diverse datasets, and human oversight in decision-making processes.
 The fine-tuning of Large Language Models (LLMs) to enhance the summarization of diagnostic screening dialogues for mental health support, particularly in resource-constrained settings. The research addresses challenges such as limited training data and domain shifts, evaluating multiple LLMs both with and without fine-tuning.[14] Using automated metrics and human evaluations, the authors assess the generalizability of these models across two datasets, further strengthening their analysis with a real-world dataset. The findings reveal that fine-tuned models significantly improve the accuracy and coherence of summaries, even with minimal data. Among the tested models, the fine-tuned BART-large-CNN achieved the best performance, outperforming existing baselines with high ROUGE scores. Additionally, the study highlights the model’s ability[14]. 
Dialogue summarization aims to condense the original dialogue into a shorter version covering salient information, which is a crucial way to reduce dialogue data overload [15]. To develop these models, we could establish rule-based models for sentiment analysis. VADER's has been adaptable to microblogging contexts that outperforms individual human raters and generalizes better across different datasets than benchmark models [16]. 
In order to deal with corpora of the transcription text, Latent Dirichlet Allocation (LDA), a generative probabilistic model for analyzing discrete data, particularly text corpora can be used as it provides structured way to extract and interpret latent themes in text data [17]. Text summarization could be performed in three steps: 1. Mining product features, 2. Identifying opinions, 3. Summarizing result [18]. While automated analysis has limitations, it is particularly effective for detecting patterns in consumer-generated text that offers decision making on selecting appropriate techniques [19]. 
The Customer Voice Sensor (CVS), ddesigned to enhance customer satisfaction analysis, CVS integrates sentiment classification, information extraction, and domain knowledge techniques to understand customer sentiments, service quality, and caller intent [20]. Comparing the advanced model for transformative role of NLP models in customer interaction, the performance of three models—T5, GPT2, and LSTM—based on predictive accuracy and computational efficiency. T5 has turn out to be the best model in terms of transformer-based NLP models with the highest accuracy and minimal error [21].
The evolution of contact centers with increasingly adopting ML and NLP solutions in the form of self-service portal and chatbots has became the importance in maintaining business operations and customer support [22]. To improve efficiency in both decision-making and technical support processes, a data mining approach using DBMiner to extract valuable insights for decision support. An integrated technique combining neural networks, case-based reasoning, and rule-based reasoning to analyze unstructured service records for machine fault diagnosis [23]. 
To deal with the automated transcription Conversation Analysis (CA) is used by comparing auto-generated transcripts with manually created ones. It evaluates transcription accuracy using both classic and modern CA recordings, highlighting strengths and limitations. While automated transcription lacks certain critical capabilities and varies in accuracy, it proves useful for generating first-pass transcripts with silences for manual refinement [24]. By integrating customer relationship marketing concepts and utilizing cognitive mapping techniques, the research highlights the most relevant factors affecting post-sales satisfaction [25].
While AI-driven conversation analysis has made significant strides, there remain areas that require further research and development. Current limitations include: Lack of Context Awareness- AI struggles with understanding sarcasm, humour, and indirect expressions, leading to misinterpretation of customer sentiment; Integration of Multiple Data Sources- While current models focus on text and voice analysis, incorporating facial expressions, body language (for video calls), and behavioural patterns could further enhance conversational intelligence; Limited Multilingual Capabilities- Many sentiment analysis models are trained primarily on English datasets, making them less effective for businesses operating in diverse linguistic environment.
This research aims to bridge these gaps by developing an AI-powered conversation analysis model that integrates multiple conversation dimensions—sentiment, intent, resolution effectiveness, and follow-up opportunities—into a unified framework. By offering real-time and post-interaction insights, our approach seeks to help businesses make more informed decisions, enhance customer experiences, and refine their communication strategies.
III.	METHODOLOGY
The Customer Call Summarizer is designed to automate the process of transcribing, analyzing, and summarizing customer service calls using AI-driven technologies. The system follows a multi-stage approach, incorporating speech-to-text conversion, speaker diarization, sentiment analysis, topic extraction, and report generation to provide a structured and insightful summary of customer interactions. This section outlines the methodology employed in developing the model, from data preprocessing to final report generation.
A.	Data Collection and Preprocessing
A The system processes both real-time and recorded customer service calls as input data. Since raw audio can be affected by background noise, inconsistent volume levels, and varying speech clarity, preprocessing is essential to ensure high-quality transcription and analysis. The preprocessing phase involves:
1)	Noise Reduction: Background noise is detected and filtered using Librosa, which extracts the key features of the audio signal while minimizing distortions
2)	Volume Normalization: Audio amplitude levels are adjusted to prevent discrepancies caused by differing microphone sensitivities.
3)	Silence Removal: Long pauses and unnecessary silences are trimmed to improve transcription efficiency.
4)	Background Sound Detection: The system identifies environmental sounds such as music, traffic, or chatter, which may indicate contextual factors influencing customer sentiment.
B.	Speech-to-Text Conversion
Once the audio is preprocessed, it is passed through an LLM API, a state-of-the-art automatic speech recognition (ASR) system. The LLM API is chosen for its high transcription accuracy, ability to handle diverse accents, and capability to process overlapping speech. The model converts speech into text while maintaining punctuation and sentence structure, ensuring that the transcribed content is readable and coherent.
C.	Speaker Diarization
Customer service conversations typically involve at least two speakers—the customer and the service representative. In cases of conference calls or escalations, more speakers may be involved. To differentiate between speakers, the system utilizes Pyannote-audio, an advanced speaker diarization model that segments the conversation into individual speaker turns. This process ensures that:
1)	Each speaker’s dialogue is correctly attributed.
2)	The conversation is structured logically, avoiding confusion between customer queries and agent responses.
3)	Sentiment and topic analysis can be performed separately on the customer and the agent to provide personalized service insights.

D.	Sentiment and Emotion Analysis
Understanding the mood and emotional state of the customer is crucial for assessing their level of satisfaction or frustration. The system employs a hybrid sentiment analysis approach that incorporates both:
1)	Text-Based Sentiment Analysis: Using RoBERTa or BERT transformers, the system analyzes the transcribed text to classify the sentiment as positive, neutral, or negative. Advanced Natural Language Processing (NLP) models further refine emotional tone detection, recognizing specific cues like anger, disappointment, satisfaction, or excitement.
2)	Voice-Based Sentiment Analysis: Since textual sentiment may lack emotional depth, Librosa is used to extract voice-based features such as pitch, tone, speech rate, and intensity. These features are analyzed to detect emotional variations in the speaker’s voice, providing deeper insights into customer emotions beyond just words.

Combining these two modalities ensures a comprehensive sentiment assessment, allowing the system to flag dissatisfied customers who may require escalation or follow-up support.
E.	Key Topic Extraction and Context Understanding
A core functionality of the summarization system is its ability to extract key topics discussed during the conversation. This is achieved using:
1)	KeyBERT (Keyword Extraction with BERT): Identifies essential topics and phrases mentioned frequently in the conversation.
2)	NLTK & SpaCy (NLP Processing): Analyzes the semantic context of words to determine the subject of the discussion (e.g., billing issues, service requests, product inquiries).
By focusing on the most relevant information, the system ensures that the generated summary highlights critical points while filtering out less significant details.
F.	Report Generation and Customer Tracking
Once sentiment, speaker attribution, and key topics are identified, the system generates a structured summary using an open-source LLM (such as LLaMA 2 or Mistral). This LLM-based approach enhances summarization by ensuring that the output:
1)	Is coherent and concise, maintaining a natural flow.
2)	Retains the core essence of the conversation while eliminating redundancy.
3)	Includes sentiment-based insights, such as whether the customer expressed satisfaction or frustration.
G.	System Integration and API Deployment
To ensure seamless usability, the Customer Call Summarizer is integrated into existing customer service platforms using a Flask-based API. The API enables:
1)	Real-time call processing, where transcripts and summaries are generated immediately after a call.
2)	Compatibility with CRM systems, ensuring that customer history and reports are readily accessible.
3)	Scalability, allowing businesses to expand usage based on volume without significant system modifications..

IV.	RESULTS
The Customer Call Summarizer was tested in real-world customer service scenarios to evaluate its performance in speech recognition, speaker separation, sentiment analysis, topic extraction, and report generation. The results demonstrate its effectiveness in automating call documentation, tracking customer interactions, and improving escalation handling and sales optimization.
The speech-to-text conversion using the LLM API achieved an average word error rate (WER) of 4.8%, handling diverse accents, background noise, and overlapping speech with high accuracy. Transcriptions retained punctuation and sentence structure, reducing the need for manual corrections.
The speaker diarization process using Pyannote-audio achieved a diarization error rate (DER) of 6.2%, effectively distinguishing between customers and service agents. This ensured proper attribution of each speaker’s dialogue, preventing confusion in summaries and improving sentiment and topic analysis.
Sentiment and emotion analysis integrated text-based (RoBERTa/BERT) and voice-based (Librosa) approaches, achieving an overall accuracy of 89%. The system identified frustration, urgency, satisfaction, and excitement, helping detect high-priority calls requiring escalation.
The key topic extraction and context analysis achieved an 87% accuracy rate, identifying key subjects such as billing complaints, product inquiries, and troubleshooting. Using KeyBERT, NLTK, and SpaCy, the system ranked key topics by relevance, ensuring concise yet informative summaries.
The background noise analysis, powered by Librosa, successfully categorized ambient sounds in 78% of cases, providing insights into customer environments such as offices, traffic, and homes.
The LLM-based report generation (LLaMA 2 or Mistral) produced 93% readable summaries, retaining key conversation points while eliminating redundancy.
V.	CONCLUSION
The Customer Call Summarizer presents a transformative approach to automating call documentation in customer service centers. By integrating advanced speech recognition, speaker diarization, sentiment analysis, and key topic extraction, the system reduces manual effort, improves efficiency, and enhances customer interaction tracking. The use of an LLM API for transcription, Pyannote-audio for speaker separation, and RoBERTa/BERT with Librosa for hybrid sentiment detection ensures high accuracy in understanding and summarizing conversations. Additionally, KeyBERT, NLTK, and SpaCy enable effective topic extraction, while an LLM-based summarization model generates coherent, structured reports for efficient decision-making.
The results demonstrate significant improvements in accuracy, efficiency, and service quality. The system successfully automates real-time call transcription, mood analysis, escalation detection, and customer tracking, with a 65% reduction in lookup time for past interactions. Additionally, it provides valuable sales insights and performance monitoring, contributing to better customer relationship management. By reducing manual report generation, customer service agents can focus more on resolving issues and improving customer experience.
Despite its effectiveness, certain areas can be improved. The speech recognition model may face challenges in highly noisy environments, and while sentiment analysis is highly accurate, deeper emotion tracking could further enhance escalation predictions. Future enhancements could involve improving background noise filtering, expanding multilingual support, and integrating real-time predictive analytics to anticipate customer needs proactively.
Overall, the Customer Call Summarizer represents a major step forward in AI-driven customer service automation. It enhances call center efficiency, improves service quality, and provides meaningful insights that help businesses better understand and serve their customers. With continuous improvements and wider adoption, such systems have the potential to redefine the future of customer support operations.
REFERENCES
[1]	Hollebeek, L. D., Sprott, D. E., & Andreassen, T. W. (2019). Customer engagement in evolving technological environments. European Journal of Marketing, 53(9), 1665-1670.
[2]	McColl-Kennedy, J. R., Zaki, M., Lemon, K. N., Urmetzer, F., & Neely, A. (2019). Gaining customer experience insights that matter. Journal of service research, 22(1), 8-26.
[3]	Pang, B., & Lee, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends® in information retrieval, 2(1–2), 1-135.
[4]	Liu, B. (2022). Sentiment analysis and opinion mining. Springer Nature.
[5]	Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019, June). Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers) (pp. 4171-4186).
[6]	Cambria, E., Poria, S., Gelbukh, A., & Thelwall, M. (2017). Sentiment analysis is a big suitcase. IEEE Intelligent Systems, 32(6), 74-80.
[7]	Mehrotra, R., Sanner, S., Buntine, W., & Xie, L. (2018). Towards a Deep Understanding of Consumer Behavior: Novel Feature Extraction and Insights from Consumer Reviews.
[8]	Gupta, S. (2009). Customer-based valuation. Journal of Interactive Marketing, 23(2), 169-178.
[9]	Hirschberg, J., & Manning, C. D. (2015). Advances in natural language processing. Science, 349(6245), 261-266.
[10]	Ligo, A. K., Kott, A., & Linkov, I. (2021). How to measure cyber-resilience of a system with autonomous agents: Approaches and challenges. IEEE Engineering Management Review, 49(2), 89-97.
[11]	Chatterjee, S., Chaudhuri, R., Vrontis, D., Thrassou, A., & Ghosh, S.K. (2021). Adoption of artificial intelligence-integrated CRM systems in agile organizations in India. Technological Forecasting and Social Change.
[12]	Binns, R., Van Kleek, M., Veale, M., Lyngs, U., Zhao, J., & Shadbolt, N. (2018, April). 'It's Reducing a Human Being to a Percentage' Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 Chi conference on human factors in computing systems (pp. 1-14).
[13]	Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias and fairness in machine learning. ACM computing surveys (CSUR), 54(6), 1-35.
[14]	Yadav, M., Sahu, N. K., Chaturvedi, M., Gupta, S., & Lone, H. R. (2024). Fine-Tuning Large Language Models for Automated Diagnostic Screening Summaries. arXiv preprint arXiv:2403.20145.
[15]	Feng, X., Feng, X., & Qin, B. (2021). A survey on dialogue summarization: Recent advances and new frontiers. arXiv preprint arXiv:2107.03175.
[16]	Hutto, C., & Gilbert, E. (2014, May). Vader: A parsimonious rule-based model for sentiment analysis of social media text. In Proceedings of the international AAAI conference on web and social media (Vol. 8, No. 1, pp. 216-225).
[17]	Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of machine Learning research, 3(Jan), 993-1022.
[18]	Hu, M., & Liu, B. (2004, August). Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 168-177).
[19]	Humphreys, A., & Wang, R. J. H. (2018). Automated text analysis for consumer research. Journal of Consumer Research, 44(6), 1274-1306.
[20]	Li, P., Yan, Y., Wang, C., Ren, Z., Cong, P., Wang, H., & Feng, J. (2016, July). Customer voice sensor: A comprehensive opinion mining system for call center conversation. In 2016 IEEE International Conference on Cloud Computing and Big Data Analysis (ICCCBDA) (pp. 324-329). IEEE.
[21]	Adebiyi, A. A., Apeh, F., Olaniyan, J., Adebiyi, M. O., Olaniyan, D., Oluwasegunfunmi, I. B., & Akindeji, K. (2024, April). Automating Customer Service Using Natural Language Processing. In 2024 International Conference on Science, Engineering and Business for Driving Sustainable Development Goals (SEB4SDG) (pp. 1-8). IEEE.
[22]	Shah, S., Ghomeshi, H., Vakaj, E., Cooper, E., & Fouad, S. (2023). A review of natural language processing in contact centre automation. Pattern Analysis and Applications, 26(3), 823-846.
[23]	Hui, S. C., & Jha, G. (2000). Data mining for customer service support. Information & Management, 38(1), 1-13.
[24]	Moore, R. J. (2015). Automated transcription and conversation analysis. Research on Language and Social Interaction, 48(3), 253-270.
[25]	de Oliveira Barreto, T. B., Pinheiro, P. R., & Silva, C. F. G. (2019). The multicriteria model support to decision in the evaluation of service quality in customer service. In Software Engineering and Algorithms in Intelligent Systems: Proceedings of 7th Computer Science On-line Conference 2018, Volume 1 7 (pp. 158-167). Springer International Publishing.

 
